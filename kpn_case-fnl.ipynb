{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Anja Marunovic\n",
    "- Email: anja.marun@gmail.com\n",
    "- Amsterdam, 23 May 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPN case Objective:\n",
    "----------------------------------\n",
    " Rebtel wants to gain insight in customers' sentiments towards Rebtel, and possible drivers for these sentiments.\n",
    " You are a Rebtel data scientist, and you've been asked to analyze the online reviews on Rebtel.\n",
    "To this end, you want to create a model that is capable of predicting the rating/sentiment an author would give.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content:\n",
    "- Import data created by scraping in R\n",
    "- Preprocess the text\n",
    "- Part I: \n",
    "  - A. Modelling reviews ~ ratings\n",
    "       - Try different models\n",
    "       - Evaluate models\n",
    "       - Perform Grid Search for best performance\n",
    "  - B. Modelling reviews ~ ratings with downsampling\n",
    "       - Try different models\n",
    "       - Evaluate models\n",
    "       - Perform Grid Search for best performance\n",
    "- Part II: \n",
    "  - A. Modelling reviews ~ positivity\n",
    "       - Try different models\n",
    "       - Evaluate models\n",
    "       - Perform Grid Search for best performance\n",
    "  - B. Modelling reviews ~ positivity with downsampling\n",
    "       - Try different models\n",
    "       - Evaluate models\n",
    "       - Perform Grid Search for best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 8000),\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def text_process(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove non-ASCII characters\n",
    "    2. Remove all punctuation\n",
    "    3. Convert to lower case\n",
    "    4. Remove all stopwords\n",
    "    5. Lemmatize words\n",
    "    6. Return the cleaned text as a list of words\n",
    "    '''\n",
    "    nopunc = [unicodedata.normalize('NFKD', char).encode('ascii', 'ignore').decode('utf-8', 'ignore') for char in text]\n",
    "    nopunc = [char for char in nopunc if char not in string.punctuation]\n",
    "    nopunc = [char.lower() for char in nopunc]\n",
    "    nopunc = [char for char in nopunc if char not in stopwords.words('english')]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    nopunc = ''.join(map(lambda c: '' if c in '0123456789' else c, nopunc))\n",
    "    \n",
    "    exclude = set(string.punctuation)\n",
    "    nopunc = ''.join(map(lambda c: '' if c in exclude else c, nopunc))\n",
    "        \n",
    "    return [lemmatizer.lemmatize(word, pos='v') for word in nopunc.split() if word not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "import string\n",
    "def text_process_2(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Lemmatize words\n",
    "    4. Return the cleaned text as a list of words\n",
    "    '''\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    return [lemmatizer.lemmatize(word, pos='v') for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebtel = pd.read_csv('C:/Users/Thomas/Desktop/Desktop/Rebtel.tsv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "# PART I\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.A     Modelling reviews ~ ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rebtel['review']\n",
    "y = rebtel['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.6038592508513053\n",
      "[[135   0   0   2  32]\n",
      " [ 37   0   1   3  16]\n",
      " [ 22   0   7  13  39]\n",
      " [ 21   0   3  16 129]\n",
      " [ 21   0   1   9 374]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.80      0.67       169\n",
      "          2       0.00      0.00      0.00        57\n",
      "          3       0.58      0.09      0.15        81\n",
      "          4       0.37      0.09      0.15       169\n",
      "          5       0.63      0.92      0.75       405\n",
      "\n",
      "avg / total       0.53      0.60      0.52       881\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# text process 2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                        ])\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_svm == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted_svm))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "#ngram_range=(1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SGDClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a449f55050f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'feature'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'importance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SGDClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "feature_df = pd.DataFrame(svm.feature_importances_.tolist(),tfidf.get_feature_names())\n",
    "feature_df.reset_index(inplace=True)\n",
    "columns = ['feature','importance']\n",
    "feature_df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM output for analyzer = text_process_2\n",
    "Overall Accuracy:  0.6038592508513053\n",
    "[[135   0   0   2  32]\n",
    " [ 37   0   1   3  16]\n",
    " [ 22   0   7  13  39]\n",
    " [ 21   0   3  16 129]\n",
    " [ 21   0   1   9 374]]\n",
    "\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          1       0.57      0.80      0.67       169\n",
    "          2       0.00      0.00      0.00        57\n",
    "          3       0.58      0.09      0.15        81\n",
    "          4       0.37      0.09      0.15       169\n",
    "          5       0.63      0.92      0.75       405\n",
    "\n",
    "avg / total       0.53      0.60      0.52       881\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.5459704880817253\n",
      "[[ 80   0   0   0  89]\n",
      " [ 17   0   0   0  40]\n",
      " [  9   0   0   0  72]\n",
      " [  5   0   0   0 164]\n",
      " [  4   0   0   0 401]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.47      0.56       169\n",
      "          2       0.00      0.00      0.00        57\n",
      "          3       0.00      0.00      0.00        81\n",
      "          4       0.00      0.00      0.00       169\n",
      "          5       0.52      0.99      0.68       405\n",
      "\n",
      "avg / total       0.37      0.55      0.42       881\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "                    ])\n",
    "text_clf = text_clf.fit(X_train,y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.5334846765039728\n",
      "[[108   5   1   9  46]\n",
      " [ 30   3   3   6  15]\n",
      " [ 20   0   6  16  39]\n",
      " [ 19   1   3  34 112]\n",
      " [ 25   2   1  58 319]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.64      0.58       169\n",
      "          2       0.27      0.05      0.09        57\n",
      "          3       0.43      0.07      0.13        81\n",
      "          4       0.28      0.20      0.23       169\n",
      "          5       0.60      0.79      0.68       405\n",
      "\n",
      "avg / total       0.49      0.53      0.49       881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_clf_rf = Pipeline([('vect', CountVectorizer(analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('rf', RandomForestClassifier()),\n",
    "                    ])\n",
    "text_clf_rf = text_clf_rf.fit(X_train,y_train)\n",
    "predicted_rf = text_clf_rf.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_rf == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted_rf))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Optimization - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf-svm__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_clf_svm_gs = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=0.001, n_iter=5, random_state=42)),\n",
    " ])\n",
    "text_clf_svm_gs = text_clf_svm_gs.fit(X_train, y_train)\n",
    "predicted_svm_gs = text_clf_svm_gs.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_svm == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted_svm_gs))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted_svm_gs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Optimization - Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_gs = Pipeline([('vect', CountVectorizer(ngram_range=(1,2),analyzer=text_process)),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', MultinomialNB(alpha=0.01)),\n",
    "                    ])\n",
    "text_clf_gs = text_clf_gs.fit(X_train,y_train)\n",
    "predicted_gs = text_clf_gs.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_gs == y_test))\n",
    "print('\\n')\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF - Optimization - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    " \n",
    "rfc = RandomForestClassifier(n_jobs=-1, max_features='sqrt', oob_score = True) \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [9, 18, 27, 36, 45, 54, 63],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30],\n",
    "           \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]}\n",
    " \n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "CV_rfc.fit(train_x, train_y)\n",
    "print CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_rf = { \n",
    "           \"n_estimators\" : [9, 18, 27, 36, 45, 54, 63],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30],\n",
    "           \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]}\n",
    "gs_clf_rf = GridSearchCV(text_clf_rf, parameters_rf, n_jobs=-1)\n",
    "gs_clf_rf = gs_clf_rf.fit(X_train, y_train)\n",
    "gs_clf_rf.best_score_\n",
    "gs_clf_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comment: \n",
    "Best result gives SVM model. However, rating 2 is poorly predicted. \n",
    "This might be due to the fact that the set is unbalanced.\n",
    "Use downsampling as the number of ratings 2  is much smaller then the number of ratings 4 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.A Modelling reviews ~ ratings with Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x154e31e6f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check distribution of scores \n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "rebtel.groupby('rating').review.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_1 = rebtel[rebtel.rating==1]\n",
    "score_2 = rebtel[rebtel.rating==2]\n",
    "score_3 = rebtel[rebtel.rating==3]\n",
    "score_4 = rebtel[rebtel.rating==4]\n",
    "score_5 = rebtel[rebtel.rating==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of reviews with score 1:  533\n",
      "Numbers of reviews with score 2:  170\n",
      "Numbers of reviews with score 3:  268\n",
      "Numbers of reviews with score 4:  563\n",
      "Numbers of reviews with score 5:  1400\n"
     ]
    }
   ],
   "source": [
    "print(\"Numbers of reviews with score 1: \",len(score_1))\n",
    "print(\"Numbers of reviews with score 2: \",len(score_2))\n",
    "print(\"Numbers of reviews with score 3: \",len(score_3))\n",
    "print(\"Numbers of reviews with score 4: \",len(score_4))\n",
    "print(\"Numbers of reviews with score 5: \",len(score_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling to n = 170 number of reviews (to balance the set)\n",
    "min_nr = 170\n",
    "import random\n",
    "score_1_downsample = score_1.sample(min_nr)\n",
    "score_2_downsample = score_2\n",
    "score_3_downsample = score_3.sample(min_nr)\n",
    "score_4_downsample = score_4.sample(min_nr)\n",
    "score_5_downsample = score_5.sample(min_nr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_2_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_downsample = score_1_downsample.append(score_2_downsample).append(score_3_downsample).append(score_4_downsample).append(score_5_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ds = set_downsample['review']\n",
    "y_ds = set_downsample['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ds, y_ds, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.396078431372549\n",
      "[[29 17  2  2  4]\n",
      " [19 17 10  8  3]\n",
      " [10  8 12  6  6]\n",
      " [ 7  6  9 14 12]\n",
      " [ 3  5  3 14 29]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.54      0.48        54\n",
      "          2       0.32      0.30      0.31        57\n",
      "          3       0.33      0.29      0.31        42\n",
      "          4       0.32      0.29      0.30        48\n",
      "          5       0.54      0.54      0.54        54\n",
      "\n",
      "avg / total       0.39      0.40      0.39       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text analyzer = text_processor 2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                        ])\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_svm == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted_svm))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM downsample - Optimization - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf-svm__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text analyzer = normalize\n",
    "text_clf_svm_gs = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=0.001, n_iter=5, random_state=42)),\n",
    " ])\n",
    "text_clf_svm_gs = text_clf_svm_gs.fit(X_train, y_train)\n",
    "predicted_svm_gs = text_clf_svm_gs.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_svm == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted_svm_gs))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted_svm_gs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II.A Modelling reviews ~ positivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebtel = pd.read_csv('C:/Users/Thomas/Desktop/Desktop/Rebtel.tsv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebtel = rebtel[rebtel['rating'] != 3]\n",
    "rebtel['positivity'] = np.where(rebtel['rating'] > 3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rebtel['review']\n",
    "y = rebtel['positivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.8925\n",
      "[[144  69]\n",
      " [ 17 570]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.68      0.77       213\n",
      "          1       0.89      0.97      0.93       587\n",
      "\n",
      "avg / total       0.89      0.89      0.89       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text processor = text_process_2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                        ])\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_svm == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted_svm))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Optimization - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf-svm__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.85\n",
      "[[126  87]\n",
      " [ 33 554]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.59      0.68       213\n",
      "          1       0.86      0.94      0.90       587\n",
      "\n",
      "avg / total       0.85      0.85      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_clf_rf = Pipeline([('vect', CountVectorizer(analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('rf', RandomForestClassifier()),\n",
    "                    ])\n",
    "text_clf_rf = text_clf_rf.fit(X_train,y_train)\n",
    "predicted_rf = text_clf_rf.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_rf == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted_rf))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF - Optimization - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a grid over parameters of interest\n",
    "parameters_rf = { \n",
    "           \"n_estimators\" : [9, 18, 27, 36, 45, 54, 63],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30],\n",
    "           \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]}\n",
    " \n",
    "gs_clf_rf = GridSearchCV(text_clf_rf, parameters_rf, n_jobs=-1)\n",
    "gs_clf_rf = gs_clf_rf.fit(X_train, y_train)\n",
    "gs_clf_rf.best_score_\n",
    "gs_clf_rf.best_params_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.7925\n",
      "[[ 47 166]\n",
      " [  0 587]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.22      0.36       213\n",
      "          1       0.78      1.00      0.88       587\n",
      "\n",
      "avg / total       0.84      0.79      0.74       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(analyzer=text_process)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "                    ])\n",
    "text_clf = text_clf.fit(X_train,y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comment:\n",
    "    All models give better result for predicting positivity\n",
    "    Next step cn be downsampling again since distribution of positivities is not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d79e2b1d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check distribution of scores \n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "rebtel.groupby('positivity').review.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebtel.groupby('positivity').review.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOWNSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_0 = rebtel[rebtel.positivity==0]\n",
    "score_1 = rebtel[rebtel.positivity==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n",
      "1963\n"
     ]
    }
   ],
   "source": [
    "print(len(score_0))\n",
    "print(len(score_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling to n = 170 number of reviews (to balance the set)\n",
    "min_nr = 703\n",
    "import random\n",
    "score_0_downsample = score_0\n",
    "score_1_downsample = score_1.sample(min_nr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_downsample = score_0_downsample.append(score_1_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = set_downsample['review']\n",
    "y_ = set_downsample['positivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train_, X_test_, y_train_, y_test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.9004739336492891\n",
      "[[190  22]\n",
      " [ 20 190]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90       212\n",
      "          1       0.90      0.90      0.90       210\n",
      "\n",
      "avg / total       0.90      0.90      0.90       422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text processor = normalize\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(analyzer=text_process_2)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                        ])\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print('Overall Accuracy: ', np.mean(predicted_svm == y_test))\n",
    "#\n",
    "print(confusion_matrix(y_test, predicted_svm))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predicted_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [['rebtel is cheap'],\n",
    "           ['rebtel is expensive'],\n",
    "           ['i called my friend in india and they charged me so much\\\n",
    "           that i have to take a credit to pay it off'],\n",
    "           ['i called kenya and they didnt charge me that much - love it'],           \n",
    "           ['customer service doesnt exist'],\n",
    "           ['customer service is great']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [['rebtel is horrible'],['rebtel is horrble'],\n",
    "       ['rebtel is bad'],['rebtel is bed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [['rebtel is so great that i will never recommend it to anyone'],\\\n",
    "        ['rebtel is amazing - when you call with rebtel the line is \\\n",
    "         breaking faster then the speed of light']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_svm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [['rebtel is not cheap'],\n",
    "           ['rebtel is not expensive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_svm.predict([['rebtel is so great that i will never recommend it to anyone'],\\\n",
    "                      ['rebtel is amazing - when you call with rebtel the line is breaking faster then the speed of light']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comment:\n",
    " For better prediction:\n",
    "    - improve cleaning: handle typos\n",
    "    - spot sarcastic expressions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
